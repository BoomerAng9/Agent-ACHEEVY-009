/**
 * ACHEEVY Orchestrator
 *
 * The real backend orchestration engine. Receives classified intents from
 * the frontend, runs the skills/hooks lifecycle, checks LUC quotas via
 * Firestore, and dispatches work to II-Agent or other Boomer_Angs.
 *
 * This replaces the frontend-only keyword routing with actual execution.
 */

import { getIIAgentClient, IIAgentClient, IIAgentTask } from '../ii-agent/client';
import { LUCEngine } from '../luc';
import { v4 as uuidv4 } from 'uuid';
import { createPipelinePacket, getN8nClient } from '../n8n';

// ── Types ────────────────────────────────────────────────────

export interface AcheevyExecuteRequest {
  userId: string;
  message: string;
  intent: string;              // from frontend classifier: plug-factory, skill:*, perform-stack, internal-llm, etc.
  conversationId?: string;
  plugId?: string;
  skillId?: string;
  skillRoute?: string;
  context?: Record<string, any>;
}

export interface AcheevyExecuteResponse {
  requestId: string;
  status: 'completed' | 'queued' | 'streaming' | 'quota_exceeded' | 'error';
  reply: string;
  data?: Record<string, any>;
  lucUsage?: {
    service: string;
    amount: number;
    remaining?: number;
  };
  taskId?: string;
  error?: string;
}

// ── Skill definitions (mirrors frontend registry for backend routing) ──

// eslint-disable-next-line @typescript-eslint/no-unused-vars
interface SkillRoute {
  id: string;
  handler: (req: AcheevyExecuteRequest, iiAgent: IIAgentClient) => Promise<AcheevyExecuteResponse>;
}

// ── Orchestrator ─────────────────────────────────────────────

export class AcheevyOrchestrator {
  private iiAgent: IIAgentClient;

  constructor() {
    this.iiAgent = getIIAgentClient();
  }

  /**
   * Main execution entry point. Takes a classified intent and executes it.
   */
  async execute(req: AcheevyExecuteRequest): Promise<AcheevyExecuteResponse> {
    const requestId = uuidv4();

    try {
      // 1. LUC quota check (lightweight - uses LUCEngine on gateway)
      //    Full Firestore-based LUC runs in aims-skills; here we do a
      //    quick local estimate to avoid round-trips for every message.
      const estimate = LUCEngine.estimate(req.message);

      // 2. Route based on classified intent
      const routedTo = req.intent;

      if (routedTo.startsWith('plug-factory:')) {
        return await this.handlePlugFabrication(requestId, req);
      }

      if (routedTo === 'perform-stack') {
        return await this.handlePerformStack(requestId, req);
      }

      if (routedTo.startsWith('skill:')) {
        return await this.handleSkillExecution(requestId, req);
      }

      if (routedTo === 'openclaw') {
        return await this.handleOpenClaw(requestId, req);
      }

      if (routedTo === 'pmo-route' || routedTo.startsWith('pmo:')) {
        return await this.handlePmoRouting(requestId, req);
      }

      // Default: conversational AI via II-Agent
      return await this.handleConversation(requestId, req, estimate);

    } catch (error: any) {
      console.error(`[ACHEEVY] Execution error for ${requestId}:`, error.message);
      return {
        requestId,
        status: 'error',
        reply: 'Something went wrong processing your request. Please try again.',
        error: error.message,
      };
    }
  }

  // ── Route Handlers ───────────────────────────────────────

  /**
   * Plug fabrication: routes build requests to II-Agent fullstack mode
   */
  private async handlePlugFabrication(
    requestId: string,
    req: AcheevyExecuteRequest
  ): Promise<AcheevyExecuteResponse> {
    const plugId = req.plugId || req.intent.split(':')[1];

    const task: IIAgentTask = {
      type: 'fullstack',
      prompt: `Build the "${plugId}" plug for A.I.M.S. User request: ${req.message}`,
      context: {
        userId: req.userId,
        sessionId: req.conversationId,
      },
      options: {
        streaming: false,
        timeout: 600000, // 10 min for builds
      },
    };

    try {
      const result = await this.iiAgent.executeTask(task);
      return {
        requestId,
        status: result.status === 'completed' ? 'completed' : 'queued',
        reply: `Plug "${plugId}" fabrication ${result.status}. ${result.output || ''}`,
        data: {
          plugId,
          artifacts: result.artifacts,
          iiAgentTaskId: result.id,
        },
        lucUsage: {
          service: 'container_hours',
          amount: 1,
        },
        taskId: result.id,
      };
    } catch {
      // II-Agent not available - queue the task
      return {
        requestId,
        status: 'queued',
        reply: `Build request for "${plugId}" has been queued. ACHEEVY will process it when the execution engine is available.`,
        taskId: `queued_${requestId}`,
      };
    }
  }

  /**
   * Perform stack: sports analytics and scouting
   */
  private async handlePerformStack(
    requestId: string,
    req: AcheevyExecuteRequest
  ): Promise<AcheevyExecuteResponse> {
    const task: IIAgentTask = {
      type: 'research',
      prompt: `Sports analytics request: ${req.message}. Analyze athlete data, provide scouting reports, and recruitment recommendations.`,
      context: {
        userId: req.userId,
        sessionId: req.conversationId,
      },
    };

    try {
      const result = await this.iiAgent.executeTask(task);
      return {
        requestId,
        status: 'completed',
        reply: result.output || 'Perform analysis complete.',
        data: { artifacts: result.artifacts },
        lucUsage: {
          service: 'brave_searches',
          amount: 5,
        },
      };
    } catch {
      return {
        requestId,
        status: 'queued',
        reply: 'Perform analytics request queued. Results will be available shortly.',
        taskId: `queued_${requestId}`,
      };
    }
  }

  /**
   * Skill execution: routes to the appropriate skill handler
   */
  private async handleSkillExecution(
    requestId: string,
    req: AcheevyExecuteRequest
  ): Promise<AcheevyExecuteResponse> {
    const skillId = req.skillId || req.intent.split(':')[1];

    // Map skill types to II-Agent task types
    const skillTaskMap: Record<string, IIAgentTask['type']> = {
      'remotion': 'code',
      'gemini-research': 'research',
      'n8n-workflow': 'code',
      'stitch': 'code',
      'best-practices': 'research',
    };

    const taskType = skillTaskMap[skillId] || 'research';

    const task: IIAgentTask = {
      type: taskType,
      prompt: `Execute A.I.M.S. skill "${skillId}". User request: ${req.message}`,
      context: {
        userId: req.userId,
        sessionId: req.conversationId,
      },
    };

    try {
      const result = await this.iiAgent.executeTask(task);
      return {
        requestId,
        status: 'completed',
        reply: result.output || `Skill "${skillId}" executed successfully.`,
        data: {
          skillId,
          artifacts: result.artifacts,
        },
        lucUsage: {
          service: 'api_calls',
          amount: 1,
        },
      };
    } catch {
      return {
        requestId,
        status: 'queued',
        reply: `Skill "${skillId}" has been queued for execution.`,
        taskId: `queued_${requestId}`,
      };
    }
  }

  /**
   * OpenClaw: multi-channel cloning/scaffolding
   */
  private async handleOpenClaw(
    requestId: string,
    req: AcheevyExecuteRequest
  ): Promise<AcheevyExecuteResponse> {
    // Forward to OpenClaw service via internal network
    try {
      const openclawUrl = process.env.OPENCLAW_URL || 'http://openclaw:18789';
      const response = await fetch(`${openclawUrl}/api/clone`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          userId: req.userId,
          message: req.message,
          conversationId: req.conversationId,
        }),
      });

      if (response.ok) {
        const data = await response.json();
        return {
          requestId,
          status: 'queued',
          reply: data.reply || 'OpenClaw is scaffolding your project.',
          taskId: data.taskId,
          lucUsage: {
            service: 'container_hours',
            amount: 1,
          },
        };
      }

      throw new Error(`OpenClaw returned ${response.status}`);
    } catch {
      return {
        requestId,
        status: 'queued',
        reply: 'Clone request received. OpenClaw will begin scaffolding when ready.',
        taskId: `queued_${requestId}`,
      };
    }
  }

  /**
   * PMO routing: classifies intent, builds directive, executes via n8n pipeline
   */
  private async handlePmoRouting(
    requestId: string,
    req: AcheevyExecuteRequest
  ): Promise<AcheevyExecuteResponse> {
    const packet = createPipelinePacket(req.userId, req.message);
    const n8n = getN8nClient();

    console.log(`[ACHEEVY] PMO routing → ${packet.classification.pmoOffice} (${packet.classification.director}), confidence: ${packet.classification.confidence.toFixed(2)}`);

    try {
      const result = await n8n.executePipeline(packet);
      return {
        requestId,
        status: result.receipt?.allPassed ? 'completed' : 'queued',
        reply: result.summary || `PMO directive routed to ${packet.classification.director}.`,
        data: {
          packetId: packet.packetId,
          pmoOffice: packet.classification.pmoOffice,
          director: packet.classification.director,
          executionLane: packet.classification.executionLane,
          complexity: packet.classification.complexity,
          receipt: result.receipt,
        },
        lucUsage: {
          service: 'api_calls',
          amount: packet.directive?.estimatedLucCost || 1,
        },
        taskId: packet.packetId,
      };
    } catch {
      return {
        requestId,
        status: 'queued',
        reply: `Your request has been classified under ${packet.classification.pmoOffice} and assigned to ${packet.classification.director}. Processing will begin shortly.`,
        data: {
          packetId: packet.packetId,
          pmoOffice: packet.classification.pmoOffice,
          director: packet.classification.director,
        },
        taskId: `queued_${requestId}`,
      };
    }
  }

  /**
   * Default conversation: routes to II-Agent for general AI chat
   */
  private async handleConversation(
    requestId: string,
    req: AcheevyExecuteRequest,
    estimate: any
  ): Promise<AcheevyExecuteResponse> {
    const taskType = IIAgentClient.mapIntentToTaskType(req.message);

    const task: IIAgentTask = {
      type: taskType,
      prompt: req.message,
      context: {
        userId: req.userId,
        sessionId: req.conversationId,
        previousMessages: req.context?.history,
      },
    };

    try {
      const result = await this.iiAgent.executeTask(task);
      return {
        requestId,
        status: 'completed',
        reply: result.output || 'Task completed.',
        data: {
          artifacts: result.artifacts,
          usage: result.usage,
          quote: estimate,
        },
        lucUsage: {
          service: 'api_calls',
          amount: result.usage?.totalTokens ? Math.ceil(result.usage.totalTokens / 1000) : 1,
        },
      };
    } catch {
      // Fallback when II-Agent is unavailable: return the estimate
      return {
        requestId,
        status: 'completed',
        reply: `I've analyzed your request: "${req.message}". The execution engine is currently warming up. Your task has been noted and will be processed shortly.`,
        data: { quote: estimate },
        lucUsage: {
          service: 'api_calls',
          amount: 1,
        },
      };
    }
  }
}

// Singleton
let orchestrator: AcheevyOrchestrator | null = null;

export function getOrchestrator(): AcheevyOrchestrator {
  if (!orchestrator) {
    orchestrator = new AcheevyOrchestrator();
  }
  return orchestrator;
}
